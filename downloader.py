# downloader.py
import aiohttp, re, urllib.parse, asyncio
from fake_useragent import UserAgent

API_BASE = "httpas://fly-wispy-wildflower-2967.fly.dev"

async def get_download_url(url: str):
    """Ø¬Ù„Ø¨ Ø³ØªÙˆØ±ÙŠØ§Øª Ø§Ù†Ø³ØªØºØ±Ø§Ù…"""
    try:
        async with aiohttp.ClientSession() as session:
            # ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ù€ username ÙŠØ¨Ø¯Ø£ Ø¨Ù€ @
            if not url.startswith("@"):
                url = f"@{url}"
            
            # Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… encoding Ù„Ù„Ù€ @
            api_url = f"{API_BASE}/highlights/stories?username={url}"
            
            print(f"ğŸ”— API Request: {api_url}")
            
            async with session.get(api_url, timeout=30) as response:
                print(f"ğŸ“¡ Response Status: {response.status}")
                
                # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø±Ø¯ Ø§Ù„Ù†ØµÙŠ Ø£ÙˆÙ„Ø§Ù‹ Ù„Ù„Ø¯ÙŠØ¨Ø§Ú¯
                text_response = await response.text()
                print(f"ğŸ“„ Raw Response: {text_response[:500]}")
                
                if response.status != 200:
                    return []
                
                # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ JSON
                try:
                    data = await response.json()
                    print(f"âœ… JSON parsed, media_urls count: {len(data.get('media_urls', []))}")
                    return data.get("media_urls", [])
                except Exception as json_error:
                    print(f"âŒ JSON parse error: {json_error}")
                    return []
    except Exception as e:
        print(f"ğŸ”¥ Error: {e}")
        return []

async def get_highlights_list(username: str):
    try:
        async with aiohttp.ClientSession() as session:
            # ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù€ username
            print(f"ğŸ‘¤ Username received: '{username}'")
            
            api_url = f"{API_BASE}/highlights/highlights_list?username=@{username}"
            print(f"ğŸ”— API URL: {api_url}")
            
            async with session.get(api_url, timeout=50) as response:
                print(f"ğŸ“¡ Response Status: {response.status}")
                
                if response.status != 200:
                    print(f"âŒ HTTP Error: {response.status}")
                    return []
                
                # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ Ø£ÙˆÙ„Ø§Ù‹ Ù„Ù„Ø¯ÙŠØ¨Ø§Ú¯
                text_response = await response.text()
                print(f"ğŸ“„ Response length: {len(text_response)} chars")
                
                # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ JSON
                try:
                    data = await response.json()
                    print(f"âœ… JSON parsed successfully, found {len(data.get('highlights', []))} highlights")
                    highlights = data.get("highlights", [])
                    
                    result = []
                    for highlight in highlights:
                        result.append((highlight["id"], highlight["title"]))
                    return result
                    
                except Exception as json_error:
                    print(f"âŒ JSON parse error: {json_error}")
                    print(f"ğŸ“„ Raw response start: {text_response[:200]}")
                    return []
    except Exception as e:
        print(f"ğŸ”¥ Exception in get_highlights_list: {type(e).__name__}: {e}")
        return []
async def get_highlight_media(highlight_id: str):
    """Ø¬Ù„Ø¨ Ø±ÙˆØ§Ø¨Ø· Ù‡Ø§ÙŠÙ„Ø§ÙŠØª Ù…Ø­Ø¯Ø¯"""
    try:
        async with aiohttp.ClientSession() as session:
            api_url = f"{API_BASE}/highlights/highlight_media?highlight_id={highlight_id}"
            async with session.get(api_url, timeout=30) as response:
                if response.status != 200:
                    return []
                
                data = await response.json()
                return data.get("media_urls", [])
    except:
        return []
async def get_download_url_with_timeout(url: str, timeout: int):
    try:
        return await asyncio.wait_for(get_download_url(url), timeout=timeout)
    except:
        return None
        
        
        
        
# downloader.py - Ø£Ø¶Ù ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
async def youtube_search(query: str):
    """Ø¨Ø­Ø« ÙÙŠ ÙŠÙˆØªÙŠÙˆØ¨"""
    try:
        import json, re, time
        from urllib.parse import quote
        
        COOKIES = {
            "VISITOR_INFO1_LIVE": "YATQpNeOy0Y",
            "VISITOR_PRIVACY_METADATA": "CgJFRxIEGgAgVg%3D%3D", 
            "PREF": "f4=4000000&f6=40000000&tz=Africa.Cairo&f7=100&hl=ar&f5=30000",
            "YSC": "8cOXet1j-2o"
        }
        
        def extract_yt_initial_data(html):
            match = re.search(r'var ytInitialData\s*=\s*({.+?});</script>', html, re.DOTALL)
            if not match:
                match = re.search(r'window\["ytInitialData"\]\s*=\s*({.+?});</script>', html, re.DOTALL)
            if not match:
                match = re.search(r'ytInitialData\s*=\s*({.+?});</script>', html, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group(1))
                except:
                    pass
            return None
        
        def find_video(data):
            if isinstance(data, dict):
                if "videoRenderer" in data:
                    return data["videoRenderer"]
                for key in ["contents", "secondaryContents", "primaryContents", "itemSectionContents"]:
                    if key in data:
                        result = find_video(data[key])
                        if result:
                            return result
                for v in data.values():
                    if isinstance(v, (dict, list)):
                        result = find_video(v)
                        if result:
                            return result
            elif isinstance(data, list):
                for item in data[:20]:
                    result = find_video(item)
                    if result:
                        return result
            return None
        
        def parse_video(vr):
            if not vr:
                return None
            url = vr.get("navigationEndpoint", {}).get("commandMetadata", {}).get("webCommandMetadata", {}).get("url", "")
            if not url.startswith("/watch"):
                return None
            is_live = vr.get("lengthText") is None
            if is_live:
                return {"error": "Ø§Ù„Ø¨Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø± ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…"}
            title = vr.get("title", {}).get("runs", [{}])[0].get("text", "N/A")
            duration = vr.get("lengthText", {}).get("simpleText")
            views = vr.get("viewCountText", {}).get("simpleText", "").replace("Ù…Ø´Ø§Ù‡Ø¯Ø©", "").replace("Ù…Ø´Ø§Ù‡Ø¯Ø§Øª", "").strip()
            channel = vr.get("ownerText", {}).get("runs", [{}])[0].get("text", "N/A")
            video_id_full = url.replace("/watch?v=", "")
            video_id = video_id_full.split("&")[0]
            return {
                "title": title,
                "duration": duration,
                "views": views,
                "channel": channel,
                "is_live": False,
                "id": video_id,
                "url": f"https://www.youtube.com/watch?v={video_id}"
            }
        
        headers = {
            "User-Agent": "Mozilla/5.0",
        }
        
        url = f"https://www.youtube.com/results?search_query={quote(query)}&hl=ar"
        async with aiohttp.ClientSession() as session:
            async with session.get(url, cookies=COOKIES, headers=headers, timeout=10) as resp:
                if resp.status != 200:
                    return {"error": "ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«"}
                html = await resp.text()
                data = extract_yt_initial_data(html)
                vr = find_video(data)
                result = parse_video(vr)
                if result:
                    return result
                else:
                    return {"error": "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"}
    
    except Exception as e:
        return {"error": f"Ø®Ø·Ø£: {str(e)}"}
        



# ÙÙŠ downloader.py Ù†Ø¶ÙŠÙ Ø¯Ø§Ù„Ø© ØªÙˆÙŠØªØ±

async def get_twitter_media(url: str):
    """Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙˆÙŠØªØ±"""
    try:
        async with aiohttp.ClientSession() as session:
            api_url = f"{API_BASE}/twitter/direct_link?url={url}"
            async with session.get(api_url) as response:
                return await response.json()
    except:
        return {"error": "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„"}


async def get_reddit_media(url: str):
    """Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª reddit"""
    try:
        async with aiohttp.ClientSession() as session:
            api_url = f"{API_BASE}/reddit/direct_link?url={url}"
            async with session.get(api_url, timeout=10) as response:
                return await response.json()
    except asyncio.TimeoutError:
        return {"error": "Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„"}
    except Exception:
        return {"error": "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„"}


async def get_pinterest_media(url: str):
    """Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨Ù†ØªØ±Ø³Øª"""
    try:
        async with aiohttp.ClientSession() as session:
            api_url = f"{API_BASE}/pinterest/direct_link?url={url}"
            async with session.get(api_url, timeout=10) as response:
                return await response.json()
    except asyncio.TimeoutError:
        return {"error": "Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„"}
    except Exception:
        return {"error": "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„"}

async def get_tiktok_media(url: str):
    """Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙŠÙƒ ØªÙˆÙƒ"""
    try:
        async with aiohttp.ClientSession() as session:
            api_url = f"{API_BASE}/tiktok/direct_link?url={url}"
            async with session.get(api_url, timeout=10) as response:
                return await response.json()
    except asyncio.TimeoutError:
        return {"error": "Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„"}
    except Exception:
        return {"error": "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„"}

async def get_tiktok_audio(url: str):
    """Ø¬Ù„Ø¨ ØµÙˆØª ØªÙŠÙƒ ØªÙˆÙƒ"""
    try:
        async with aiohttp.ClientSession() as session:
            api_url = f"{API_BASE}/tiktok/direct_audio?url={url}"
            async with session.get(api_url, timeout=10) as response:
                return await response.json()
    except asyncio.TimeoutError:
        return {"error": "Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„"}
    except Exception:
        return {"error": "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„"}


async def get_instagram_media_info(url: str):
    """Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù„Ù Ø§Ù†Ø³ØªØºØ±Ø§Ù…"""
    try:
        async with aiohttp.ClientSession() as session:
            api_url = f"{API_BASE}/instagram/direct_link?url={url}"
            async with session.get(api_url) as response:
                return await response.json()
    except:
        return {"error": "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„"}

async def get_instagram_audio(url: str):
    """Ø¬Ù„Ø¨ Ø±Ø§Ø¨Ø· ØµÙˆØª Ø§Ù†Ø³ØªØºØ±Ø§Ù…"""
    try:
        async with aiohttp.ClientSession() as session:
            api_url = f"{API_BASE}/instagram/direct_audio?url={url}"
            async with session.get(api_url) as response:
                return await response.json()
    except:
        return {"error": "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„"}

async def get_facebook_media(url: str, max_retries: int = 2):
    """Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠØ³Ø¨ÙˆÙƒ Ù…Ø¹ Ù…Ù‡Ù„Ø© 3 Ø«ÙˆØ§Ù†ÙŠ ÙˆÙ…Ø­Ø§ÙˆÙ„Ø© Ø«Ø§Ù†ÙŠØ©"""
    for attempt in range(max_retries):
        try:
            async with aiohttp.ClientSession() as session:
                api_url = f"{API_BASE}/facebook/direct_link?url={url}"
                
                # Ø§Ø³ØªØ®Ø¯Ù… wait_for Ù„ØªØ¹ÙŠÙŠÙ† Ù…Ù‡Ù„Ø© 3 Ø«ÙˆØ§Ù†ÙŠ
                async with session.get(api_url) as response:
                    # Ù…Ù‡Ù„Ø© 3 Ø«ÙˆØ§Ù†ÙŠ Ù„ÙƒÙ„ Ù…Ø­Ø§ÙˆÙ„Ø©
                    result = await asyncio.wait_for(response.json(), timeout=3)
                    return result
                    
        except asyncio.TimeoutError:
            if attempt < max_retries - 1:
                print(f"Ø§Ù†ØªÙ‡Øª Ø§Ù„Ù…Ù‡Ù„Ø©ØŒ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 2} Ù…Ù† {max_retries}")
                continue  # Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰
            else:
                return {"error": "Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¹Ø¯ Ø¹Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø§Øª"}
        except aiohttp.ClientError as e:
            return {"error": f"ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„: {str(e)}"}
        except Exception as e:
            return {"error": f"Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}"}
    
    return {"error": "ÙØ´Ù„ Ø¨Ø¹Ø¯ Ø¹Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø§Øª"}

async def get_snapchat_media(url: str):
    """Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø³Ù†Ø§Ø¨ Ø´Ø§Øª"""
    try:
        async with aiohttp.ClientSession() as session:
            api_url = f"{API_BASE}/snapchat/direct_link?url={url}"
            async with session.get(api_url) as response:
                return await response.json()
    except:
        return {"error": "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„"}
